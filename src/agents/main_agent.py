"""
DeepAgents AraÅŸtÄ±rma Sistemi
Firecrawl MCP + Gemini 2.5 Flash
FINAL WORKING VERSION
"""
import asyncio
import os
import time
from typing import Optional

from deepagents import create_deep_agent
from langchain.chat_models import init_chat_model
from langchain_mcp_adapters.client import MultiServerMCPClient

from ..config import settings


# ============ LANGSMITH ============

def setup_langsmith():
    """LangSmith tracing'i etkinleÅŸtirir"""
    os.environ.setdefault("LANGCHAIN_TRACING_V2", "true")
    os.environ.setdefault("LANGCHAIN_PROJECT", "multi-agent-search")
    if settings.langsmith_api_key:
        os.environ["LANGCHAIN_API_KEY"] = settings.langsmith_api_key
        print("[OK] LangSmith tracing aktif!")
        print("   ğŸ“Š https://smith.langchain.com")
        return True
    return False


# ============ MODEL ============

def get_llm_model():
    """KullanÄ±labilir LLM modelini dÃ¶ndÃ¼rÃ¼r"""
    model_string = settings.get_available_model()
    provider, model_name = settings.get_model_provider(model_string)
    print(f"[MODEL] Model: {provider}:{model_name}")
    
    if provider == "google_genai" and settings.google_api_key:
        os.environ["GOOGLE_API_KEY"] = settings.google_api_key
    if provider == "ollama":
        os.environ["OLLAMA_HOST"] = settings.ollama_base_url
        
    return init_chat_model(model_string, temperature=0.3)  # Daha tutarlÄ± sonuÃ§lar iÃ§in


# ============ SYSTEM PROMPT ============

RESEARCH_INSTRUCTIONS = """You are an expert Turkish Research AI (DeepAgent) that creates professional, comprehensive reports.

ğŸ¯ YOUR MISSION:
1. PLAN with write_todos
2. SEARCH using tools
3. SAVE context to files (write_file)
4. CREATE final report
5. STOP immediately

ğŸ› ï¸ DEEPAGENT TOOLS (Built-in):
- write_todos: Create task plan
- read_file/write_file/edit_file/ls: File system for context management
- task: Spawn subagent for complex subtasks

ğŸ” RESEARCH TOOLS:
- firecrawl_search(query) - Deep web scraping
- tavily-search(query, max_results) - AI-powered search
- github_search_repositories(query) - Find code repositories
- firecrawl_scrape(url) - Extract full page content

ğŸ“‹ WORKFLOW:
1. write_todos: ["Analyze query", "Search web", "Save results", "Write report"]
2. Search with research tools
3. write_file: Save long results to "research_data.md" (prevent context overflow)
4. Generate final report
5. Done!

ğŸ“‹ PROFESSIONAL REPORT FORMAT (ALWAYS IN TURKISH):

# ğŸ“Š [BaÅŸlÄ±k - AÃ§Ä±klayÄ±cÄ± ve Profesyonel]

---

## ğŸ¯ Ã–zet
[2-3 cÃ¼mle ile konunun Ã¶zÃ¼. Net, anlaÅŸÄ±lÄ±r ve ilgi Ã§ekici yazÄ±n.]

---

## ğŸ“– DetaylÄ± AÃ§Ä±klama

### [SEARCH] Nedir?
[Ä°lk paragraf: Konunun tanÄ±mÄ±, ne olduÄŸu, temel Ã¶zellikleri]

### ğŸ’¡ NasÄ±l Ã‡alÄ±ÅŸÄ±r?
[Ä°kinci paragraf: Ã‡alÄ±ÅŸma prensibi, arkasÄ±ndaki mantÄ±k]

### âš¡ Neden Ã–nemli?
[ÃœÃ§Ã¼ncÃ¼ paragraf: AvantajlarÄ±, kullanÄ±m nedenleri, faydalarÄ±]

---

## ğŸ’» Kod Ã–rnekleri

### Ã–rnek 1: Temel KullanÄ±m
```python
# Basit ve anlaÅŸÄ±lÄ±r Ã¶rnek
# Her satÄ±rÄ± aÃ§Ä±klayÄ±n

# Ã–rnek kod buraya
```
**AÃ§Ä±klama:** [Bu kodun ne yaptÄ±ÄŸÄ±nÄ± aÃ§Ä±klayÄ±n]

### Ã–rnek 2: GeliÅŸmiÅŸ KullanÄ±m
```python
# Daha karmaÅŸÄ±k, gerÃ§ek dÃ¼nya Ã¶rneÄŸi
# Pratik bir senaryo gÃ¶sterin

# Ã–rnek kod buraya
```
**AÃ§Ä±klama:** [Bu kodun ne yaptÄ±ÄŸÄ±nÄ± aÃ§Ä±klayÄ±n]

### Ã–rnek 3: Best Practices
```python
# En iyi uygulamalar
# Profesyonel kullanÄ±m

# Ã–rnek kod buraya
```
**AÃ§Ä±klama:** [Bu kodun ne yaptÄ±ÄŸÄ±nÄ± aÃ§Ä±klayÄ±n]

---

## ğŸ¯ KullanÄ±m AlanlarÄ±

| Alan | AÃ§Ä±klama |
|------|----------|
| ğŸ”¹ **[Alan 1]** | [KÄ±sa aÃ§Ä±klama] |
| ğŸ”¹ **[Alan 2]** | [KÄ±sa aÃ§Ä±klama] |
| ğŸ”¹ **[Alan 3]** | [KÄ±sa aÃ§Ä±klama] |

---

## [OK] Avantajlar & [ERROR] Dezavantajlar

### [OK] Avantajlar:
- âœ“ [Avantaj 1]
- âœ“ [Avantaj 2]
- âœ“ [Avantaj 3]

### [ERROR] Dezavantajlar:
- âœ— [Dezavantaj 1]
- âœ— [Dezavantaj 2]

---

## [START] HÄ±zlÄ± BaÅŸlangÄ±Ã§

1. **Kurulum:**
   ```bash
   # Kurulum komutu
   ```

2. **Ä°lk AdÄ±mlar:**
   - [AdÄ±m 1]
   - [AdÄ±m 2]
   - [AdÄ±m 3]

---

## ğŸ“š Kaynaklar

1. ğŸ”— [Kaynak BaÅŸlÄ±ÄŸÄ±](URL) - KÄ±sa aÃ§Ä±klama
2. ğŸ”— [Kaynak BaÅŸlÄ±ÄŸÄ±](URL) - KÄ±sa aÃ§Ä±klama
3. ğŸ”— [Kaynak BaÅŸlÄ±ÄŸÄ±](URL) - KÄ±sa aÃ§Ä±klama

---

## ğŸ’¡ Ä°puÃ§larÄ± & Notlar

> **ğŸ’¡ Ä°pucu:** [Ã–nemli bir ipucu]

> **[WARN] Dikkat:** [UyarÄ± veya Ã¶nemli not]

> **ğŸ“ Ã–ÄŸrenme KaynaÄŸÄ±:** [Ek Ã¶ÄŸrenme materyali]

---

**ğŸ“… Rapor Tarihi:** {bugÃ¼nÃ¼n tarihi}  
**[SEARCH] Arama KaynaÄŸÄ±:** [KullanÄ±lan tool]

---

ğŸ¯ CRITICAL RULES:
- Search ONLY ONCE with the most relevant tool
- ALWAYS include minimum 3 code examples with explanations
- Write minimum 3 detailed paragraphs in "DetaylÄ± AÃ§Ä±klama"
- Use emojis for better readability (ğŸ“Š ğŸ¯ ğŸ’» [OK] etc.)
- Include tables, lists, and formatted sections
- Add practical tips and warnings
- STOP immediately after writing the report
- Write EVERYTHING in Turkish (except code)

ğŸ“ EXAMPLE QUERY: "Python pandas nedir?"
[OK] YOU SHOULD:
1. tavily-search(query="Python pandas tutorial examples best practices", max_results=5)
2. Write comprehensive report with:
   - Professional title with emoji
   - 3+ detailed paragraphs
   - 3 code examples with explanations
   - Use cases table
   - Pros & cons
   - Quick start guide
   - Multiple sources
   - Tips & warnings
3. STOP

[ERROR] NEVER:
- Search more than once
- Write short, incomplete reports
- Skip code examples
- Write in English (except code comments)
"""


# ============ AGENT OLUÅTURMA ============

def sanitize_tool_schema(tool):
    """MCP tool schema'larÄ±nÄ± Gemini uyumlu hale getirir"""
    if hasattr(tool, 'args_schema') and tool.args_schema:
        schema = tool.args_schema
        if hasattr(schema, 'schema'):
            schema_dict = schema.schema()
            # Gemini ile uyumsuz alanlarÄ± kaldÄ±r
            schema_dict.pop('$schema', None)
            schema_dict.pop('additionalProperties', None)
            if 'properties' in schema_dict:
                for prop in schema_dict['properties'].values():
                    if isinstance(prop, dict):
                        prop.pop('$schema', None)
                        prop.pop('additionalProperties', None)
    return tool


async def create_research_agent():
    """Firecrawl MCP + DeepAgent oluÅŸturur"""
    
    setup_langsmith()
    
    if not settings.firecrawl_api_key:
        raise ValueError("[ERROR] FIRECRAWL_API_KEY gerekli! .env dosyasÄ±nÄ± kontrol edin.")
    
    print("\nğŸ”Œ MCP Servers baÄŸlanÄ±yor...")
    
    # Her MCP'yi ayrÄ± ayrÄ± test et
    working_servers = {}
    
    # 1. Firecrawl (zorunlu)
    print("   ğŸ”¥ Firecrawl test ediliyor...")
    try:
        test_client = MultiServerMCPClient({
            "firecrawl": {
                "command": settings.firecrawl_mcp_command,
                "args": settings.firecrawl_mcp_args,
                "env": settings.get_firecrawl_env(),
                "transport": "stdio"
            }
        })
        test_tools = await test_client.get_tools()
        if test_tools:
            working_servers["firecrawl"] = {
                "command": settings.firecrawl_mcp_command,
                "args": settings.firecrawl_mcp_args,
                "env": settings.get_firecrawl_env(),
                "transport": "stdio"
            }
            print(f"      [OK] Firecrawl OK ({len(test_tools)} tools)")
    except Exception as e:
        print(f"      [ERROR] Firecrawl baÅŸarÄ±sÄ±z: {str(e)[:100]}")
        raise ValueError("Firecrawl MCP zorunlu ama baÅŸlatÄ±lamadÄ±!")
    
    # 2. Tavily (opsiyonel)
    if hasattr(settings, 'tavily_api_key') and settings.tavily_api_key:
        print("   [SEARCH] Tavily test ediliyor...")
        try:
            test_client = MultiServerMCPClient({
                "tavily": {
                    "command": "npx",
                    "args": ["-y", "tavily-mcp@latest"],
                    "env": {"TAVILY_API_KEY": settings.tavily_api_key},
                    "transport": "stdio"
                }
            })
            test_tools = await test_client.get_tools()
            if test_tools:
                working_servers["tavily"] = {
                    "command": "npx",
                    "args": ["-y", "tavily-mcp@latest"],
                    "env": {"TAVILY_API_KEY": settings.tavily_api_key},
                    "transport": "stdio"
                }
                print(f"      [OK] Tavily OK ({len(test_tools)} tools)")
        except Exception as e:
            print(f"      [WARN] Tavily atlandÄ±: {str(e)[:100]}")
    
    # 3. GitHub (opsiyonel) - Community package via npx
    # Not: GitHub'Ä±n resmi MCP'si Docker gerektirir, bu yÃ¼zden community versiyonunu kullanÄ±yoruz
    if hasattr(settings, 'github_token') and settings.github_token:
        print("   ğŸ’» GitHub test ediliyor...")
        try:
            test_client = MultiServerMCPClient({
                "github": {
                    "command": "npx",
                    "args": ["-y", "@modelcontextprotocol/server-github"],
                    "env": {"GITHUB_PERSONAL_ACCESS_TOKEN": settings.github_token},
                    "transport": "stdio"
                }
            })
            test_tools = await test_client.get_tools()
            if test_tools:
                working_servers["github"] = {
                    "command": "npx",
                    "args": ["-y", "@modelcontextprotocol/server-github"],
                    "env": {"GITHUB_PERSONAL_ACCESS_TOKEN": settings.github_token},
                    "transport": "stdio"
                }
                print(f"      [OK] GitHub OK ({len(test_tools)} tools)")
        except Exception as e:
            print(f"      [WARN] GitHub atlandÄ±: {str(e)[:100]}")
    
    # Final MCP client - sadece Ã§alÄ±ÅŸan serverlarla
    print(f"\n[OK] {len(working_servers)} MCP server aktif: {', '.join(working_servers.keys())}")
    mcp_client = MultiServerMCPClient(working_servers)
    mcp_tools = await mcp_client.get_tools()
    print(f"   ğŸ“‹ Toplam {len(mcp_tools)} tool yÃ¼klendi")
    
    # Tool schema'larÄ±nÄ± Gemini uyumlu hale getir
    for tool in mcp_tools:
        sanitize_tool_schema(tool)
    
    # LLM modelini al
    model = get_llm_model()
    
    print("[MODEL] Model:", model.model_name if hasattr(model, 'model_name') else "Unknown")
    
    # DeepAgent oluÅŸtur
    # deepagents venv sÃ¼rÃ¼mÃ¼: `system_prompt` kullanÄ±r (instructions deÄŸil)
    agent = create_deep_agent(
        model=model,
        tools=mcp_tools,
        system_prompt=RESEARCH_INSTRUCTIONS,
    )
    
    print("[OK] DeepAgent hazÄ±r!\n")
    return agent, mcp_client


# ============ ARAÅTIRMA Ã‡ALIÅTIRMA ============

async def run_research(question: str, verbose: bool = True) -> str:
    """AraÅŸtÄ±rma agent'Ä±nÄ± Ã§alÄ±ÅŸtÄ±rÄ±r"""
    
    if verbose:
        print("\n" + "=" * 70)
        print("ğŸ”¬ DeepAgents AraÅŸtÄ±rma Sistemi")
        print("   Gemini 2.5 Flash + Firecrawl MCP")
        print("=" * 70)
        print(f"\nğŸ“ Soru: {question}\n")
    
    agent = None
    mcp_client = None
    max_retries = 3
    
    for attempt in range(max_retries):
        try:
            # Agent'Ä± oluÅŸtur
            agent, mcp_client = await create_research_agent()
            
            if verbose:
                print("[START] AraÅŸtÄ±rma baÅŸlatÄ±lÄ±yor...\n")
            
            # Rate limit iÃ§in baÅŸlangÄ±Ã§ bekleme
            if attempt > 0:
                wait = 10 * attempt
                print(f"â³ {wait} saniye bekleniyor (rate limit)...")
                await asyncio.sleep(wait)
            
            # Agent'Ä± Ã§alÄ±ÅŸtÄ±r (recursion_limit ile sonsuz dÃ¶ngÃ¼yÃ¼ engelle)
            result = await agent.ainvoke(
                {"messages": [{"role": "user", "content": question}]},
                config={"recursion_limit": 15}  # ArtÄ±rÄ±ldÄ±: 10 â†’ 15
            )
            
            # --- DEBUG LOGGING ---
            if verbose:
                print(f"\nğŸ“¦ DEBUG INFO:")
                print(f"   Result Keys: {list(result.keys())}")
                
                if "messages" in result:
                    print(f"   Message Count: {len(result['messages'])}")
                    
                    # Her mesajÄ± incele
                    for i, msg in enumerate(result['messages']):
                        msg_type = type(msg).__name__
                        print(f"\n   ğŸ”¹ Message {i}: {msg_type}")
                        
                        # Content
                        if hasattr(msg, 'content'):
                            content = msg.content
                            content_preview = str(content)[:200]
                            print(f"      Content: {content_preview}...")
                        
                        # Tool calls
                        if hasattr(msg, 'tool_calls') and msg.tool_calls:
                            print(f"      ğŸ”§ Tool Calls: {len(msg.tool_calls)}")
                            for tc in msg.tool_calls:
                                print(f"         - {tc.get('name', 'unknown')}({list(tc.get('args', {}).keys())})")
                        
                        # Tool results
                        if hasattr(msg, 'name'):
                            print(f"      Tool Result from: {msg.name}")
            
            print("\n" + "-" * 70)
            
            # Son AI mesajÄ±nÄ± bul ve dÃ¶ndÃ¼r
            final_response = ""
            
            if "messages" in result and result["messages"]:
                # Sondan baÅŸa doÄŸru git
                for msg in reversed(result["messages"]):
                    # Sadece AI mesajlarÄ±nÄ± al
                    if type(msg).__name__ not in ['AIMessage', 'AIMessageChunk']:
                        continue
                    
                    if not hasattr(msg, 'content'):
                        continue
                    
                    content = msg.content
                    
                    # String ise direkt al
                    if isinstance(content, str) and content.strip():
                        final_response = content.strip()
                        break
                    
                    # List ise text parÃ§alarÄ±nÄ± birleÅŸtir
                    elif isinstance(content, list):
                        texts = []
                        for item in content:
                            if isinstance(item, dict) and 'text' in item:
                                texts.append(item['text'])
                            elif isinstance(item, str):
                                texts.append(item)
                        
                        if texts:
                            final_response = ' '.join(texts).strip()
                            break
                        
                        combined = "\n".join(texts).strip()
                        if combined:
                            final_response = combined
                            break
            
            # Sonucu gÃ¶ster
            if verbose and final_response:
                print("\n" + "=" * 70)
                print("ğŸ“Š SONUÃ‡")
                print("=" * 70 + "\n")
                print(final_response)
                print("\n" + "=" * 70)
            
            if not final_response:
                print("\n[ERROR] UYARI: Agent yanÄ±t Ã¼retti ama iÃ§erik bulunamadÄ±!")
                print("   YukarÄ±daki debug loglarÄ±nÄ± kontrol edin.")
                return "[ERROR] AraÅŸtÄ±rma tamamlandÄ± ama yanÄ±t formatlanamadÄ±. Debug loglarÄ±na bakÄ±n."
            
            return final_response
        
        except Exception as e:
            error_msg = str(e)
            
            # Rate limit hatasÄ±
            if "429" in error_msg or "Resource exhausted" in error_msg or "quota" in error_msg.lower():
                wait_time = 30 * (attempt + 1)
                print(f"\n[WARN] Rate limit aÅŸÄ±ldÄ± (429 Error)")
                print(f"   {wait_time} saniye bekleniyor... (Deneme {attempt+1}/{max_retries})")
                
                # MCP client'Ä± kapat
                if mcp_client:
                    try:
                        if hasattr(mcp_client, 'close'):
                            await mcp_client.close()
                        elif hasattr(mcp_client, '__aexit__'):
                            await mcp_client.__aexit__(None, None, None)
                    except Exception:
                        pass
                
                await asyncio.sleep(wait_time)
                continue
            
            # DiÄŸer hatalar
            error_msg = f"[ERROR] Hata: {str(e)}"
            if verbose:
                print(f"\n{error_msg}")
                import traceback
                traceback.print_exc()
            
            return error_msg
        
        finally:
            # MCP client'Ä± her durumda kapat
            if mcp_client:
                try:
                    if hasattr(mcp_client, 'close'):
                        await mcp_client.close()
                    elif hasattr(mcp_client, '__aexit__'):
                        await mcp_client.__aexit__(None, None, None)
                except Exception as close_error:
                    if verbose:
                        print(f"[WARN] MCP client kapatma hatasÄ±: {close_error}")
    
    return "[ERROR] Maksimum deneme sayÄ±sÄ±na ulaÅŸÄ±ldÄ±. LÃ¼tfen birkaÃ§ dakika sonra tekrar deneyin."


def run_research_sync(question: str, verbose: bool = True) -> str:
    """Senkron wrapper - CLI iÃ§in"""
    return asyncio.run(run_research(question, verbose))


# ============ Ä°NTERAKTÄ°F MOD ============

async def interactive_mode():
    """Ä°nteraktif mod - Terminal'den sÃ¼rekli soru sorabilirsiniz"""
    print("\n" + "=" * 70)
    print("ğŸ”¬ Ä°nteraktif AraÅŸtÄ±rma Modu")
    print("=" * 70)
    print("\nKomutlar:")
    print("  - Soru yazÄ±n ve Enter'a basÄ±n")
    print("  - 'q' veya 'quit' -> Ã‡Ä±kÄ±ÅŸ")
    print("  - 'clear' -> EkranÄ± temizle")
    print("\n" + "=" * 70 + "\n")
    
    while True:
        try:
            question = input("ğŸ“ Soru: ").strip()
            
            if question.lower() in ['q', 'quit', 'exit']:
                print("\nğŸ‘‹ GÃ¶rÃ¼ÅŸmek Ã¼zere!")
                break
            
            if question.lower() == 'clear':
                os.system('cls' if os.name == 'nt' else 'clear')
                continue
            
            if not question:
                continue
            
            # AraÅŸtÄ±rmayÄ± Ã§alÄ±ÅŸtÄ±r
            result = await run_research(question, verbose=True)
            
            print("\n" + "-" * 70 + "\n")
            
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ GÃ¶rÃ¼ÅŸmek Ã¼zere!")
            break
        except Exception as e:
            print(f"\n[ERROR] Beklenmeyen hata: {e}")
            import traceback
            traceback.print_exc()