"""
Multi-Agent Research System - FIXED VERSION
GerÃ§ek Ã§oklu ajan mimarisi - Supervisor + Researcher + Coder + Writer
LangSmith Tracing desteÄŸi
"""

import os
from typing import Annotated, Literal, TypedDict, List
from pydantic import BaseModel, Field
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langchain_core.messages import HumanMessage, AIMessage
from langchain_mcp_adapters.client import MultiServerMCPClient
from src.config import settings
from src.models import get_llm_model, sanitize_tool_schema
from deepagents import create_deep_agent
import logging

# Logging setup
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ============ LANGSMITH TRACING ============
def setup_langsmith():
    """LangSmith tracing'i aktifleÅŸtir"""
    if settings.langsmith_api_key:
        os.environ.setdefault("LANGCHAIN_TRACING_V2", "true")
        os.environ.setdefault("LANGCHAIN_PROJECT", "ai-research-multi-agent")
        os.environ["LANGCHAIN_API_KEY"] = settings.langsmith_api_key
        logger.info("[LANGSMITH] Tracing aktif: ai-research-multi-agent")
        return True
    return False

_langsmith_enabled = setup_langsmith()


# =============================================================================
# PYDANTIC MODELS (STRUCTURED OUTPUT)
# =============================================================================

class SupervisorPlan(BaseModel):
    """Supervisor'Ä±n oluÅŸturduÄŸu plan"""
    agents: List[str] = Field(description="Ã‡alÄ±ÅŸacak agentlarÄ±n sÄ±rasÄ±")
    reason: str = Field(description="Bu planÄ±n seÃ§ilme sebebi")
    estimated_time: str = Field(default="2-3 dakika", description="Tahmini sÃ¼re")


# =============================================================================
# STATE DEFINITION
# =============================================================================

class AgentState(TypedDict):
    """TÃ¼m agentlar arasÄ±nda paylaÅŸÄ±lan state"""
    messages: Annotated[list, add_messages]
    query: str
    research_results: str
    code_examples: str
    final_report: str
    next_agent: str
    supervisor_plan: str
    supervisor_reason: str


# =============================================================================
# AGENT PROMPTS
# =============================================================================

SUPERVISOR_PROMPT = """Sen bir AraÅŸtÄ±rma YÃ¶neticisisin. KullanÄ±cÄ±nÄ±n sorusunu analiz et ve EN UYGUN agent stratejisini belirle.

KullanÄ±labilir Agentlar:
- researcher: Web aramasÄ±, genel bilgi toplama (Firecrawl, Tavily)
- coder: Kod Ã¶rnekleri, teknik implementasyon
- writer: Final rapor yazma

Soru Analizi:
{query}

Soruyu analiz et ve ÅŸu kriterlere gÃ¶re karar ver:

1. **Sadece Bilgi Ä°stiyorsa** â†’ researcher â†’ writer
   Ã–rnek: "Python nedir?", "DeepAgents nedir?"
   
2. **Kod Ä°stiyorsa** â†’ researcher â†’ coder â†’ writer
   Ã–rnek: "Python ile veri analizi nasÄ±l yapÄ±lÄ±r?", "Kod Ã¶rnekleri gÃ¶ster"
   
3. **Sadece Kod Ä°stiyorsa** â†’ coder â†’ writer
   Ã–rnek: "Python pandas kod Ã¶rneÄŸi", "FastAPI authentication kodu"

4. **KarmaÅŸÄ±k AraÅŸtÄ±rma** â†’ researcher â†’ coder â†’ writer
   Ã–rnek: "Machine learning projeleri ve implementasyonu"

CEVAP FORMATI (SADECE BU FORMATTA YAZ):
Plan: [agent1] -> [agent2] -> [agent3]
Sebep: [KÄ±sa aÃ§Ä±klama]

Ã–rnek:
Plan: researcher -> coder -> writer
Sebep: Soru hem bilgi hem kod gerektiriyor
"""

RESEARCHER_PROMPT = """Sen bir AraÅŸtÄ±rmacÄ± AjansÄ±n. GÃ¶revin:

1. KullanÄ±cÄ±nÄ±n sorusunu araÅŸtÄ±r
2. Firecrawl veya Tavily ile web aramasÄ± yap
3. BulduÄŸun bilgileri Ã¶zetle

Soru: {query}

AraÅŸtÄ±rma yap ve bulgularÄ±nÄ± TÃ¼rkÃ§e Ã¶zetle. KaynaklarÄ± belirt.
"""

CODER_PROMPT = """Sen bir Kod UzmanÄ±sÄ±n. GÃ¶revin:

1. Konuyla ilgili kod Ã¶rnekleri bul veya oluÅŸtur
2. En az 3 farklÄ± Ã¶rnek hazÄ±rla (basit, orta, geliÅŸmiÅŸ)
3. Her Ã¶rneÄŸi aÃ§Ä±kla

Konu: {query}
AraÅŸtÄ±rma SonuÃ§larÄ±: {research_results}

3 kod Ã¶rneÄŸi oluÅŸtur ve aÃ§Ä±kla. TÃ¼rkÃ§e yaz.
"""

WRITER_PROMPT = """Sen bir Profesyonel Rapor YazarÄ±sÄ±n. GÃ¶revin:

AÅŸaÄŸÄ±daki bilgileri kullanarak kapsamlÄ± bir TÃ¼rkÃ§e rapor yaz:

Soru: {query}
AraÅŸtÄ±rma: {research_results}
Kod Ã–rnekleri: {code_examples}

Rapor FormatÄ±:
# ğŸ“Š [BaÅŸlÄ±k]

## ğŸ¯ Ã–zet
[2-3 cÃ¼mle]

## ğŸ“– DetaylÄ± AÃ§Ä±klama
### [SEARCH] Nedir?
[Paragraf]

### ğŸ’¡ NasÄ±l Ã‡alÄ±ÅŸÄ±r?
[Paragraf]

### âš¡ Neden Ã–nemli?
[Paragraf]

## ğŸ’» Kod Ã–rnekleri
{code_examples}

## ğŸ¯ KullanÄ±m AlanlarÄ±
[Tablo]

## [OK] Avantajlar & [ERROR] Dezavantajlar

## [START] HÄ±zlÄ± BaÅŸlangÄ±Ã§

## ğŸ“š Kaynaklar

## ğŸ’¡ Ä°puÃ§larÄ± & Notlar

Profesyonel, detaylÄ± ve gÃ¶rsel bir rapor yaz!
"""


# =============================================================================
# AGENT NODES (DEEPAGENTS POWERED + ERROR HANDLING)
# =============================================================================

async def supervisor_node(state: AgentState) -> AgentState:
    """YÃ¶netici: Hangi agentlarÄ±n Ã§alÄ±ÅŸacaÄŸÄ±na karar verir"""
    try:
        logger.info("ğŸ¯ Supervisor baÅŸladÄ±...")
        model = get_llm_model()
        
        supervisor = create_deep_agent(
            model=model,
            tools=[],
            system_prompt=SUPERVISOR_PROMPT.format(query=state["query"]),
        )
        
        result = await supervisor.ainvoke(
            {"messages": [{"role": "user", "content": state["query"]}]},
            config={"recursion_limit": 15}  # ArtÄ±rÄ±ldÄ±: 3 â†’ 15
        )
        
        response_content = ""
        if "messages" in result:
            for msg in reversed(result["messages"]):
                if hasattr(msg, 'content') and isinstance(msg.content, str):
                    response_content = msg.content
                    break
        
        # Plan'Ä± parse et
        plan_line = ""
        reason_line = ""
        for line in response_content.split('\n'):
            if line.strip().startswith("Plan:"):
                plan_line = line.replace("Plan:", "").strip()
            elif line.strip().startswith("Sebep:"):
                reason_line = line.replace("Sebep:", "").strip()
        
        agents_order = plan_line.lower() if plan_line else response_content.lower()
        
        # Ä°lk agentÄ± belirle
        if "researcher" in agents_order:
            state["next_agent"] = "researcher"
        elif "coder" in agents_order:
            state["next_agent"] = "coder"
        else:
            # Fallback: Query analizi
            query_lower = state["query"].lower()
            if any(word in query_lower for word in ["kod", "code", "Ã¶rnek", "example"]):
                state["next_agent"] = "coder"
            else:
                state["next_agent"] = "researcher"
        
        state["supervisor_plan"] = agents_order
        state["supervisor_reason"] = reason_line
        
        state["messages"].append(AIMessage(
            content=f"ğŸ¯ Plan: {agents_order}\nğŸ’¡ Sebep: {reason_line}" if reason_line 
            else f"ğŸ¯ Plan: {agents_order}"
        ))
        
        logger.info(f"[OK] Supervisor tamamlandÄ±. Next: {state['next_agent']}")
        
    except Exception as e:
        logger.error(f"[ERROR] Supervisor Error: {str(e)}", exc_info=True)
        state["messages"].append(AIMessage(content=f"âš ï¸ Supervisor hatasÄ±, varsayÄ±lan plan"))
        state["next_agent"] = "researcher"
        state["supervisor_plan"] = "researcher -> coder -> writer"
        state["supervisor_reason"] = "VarsayÄ±lan plan (hata)"
    
    return state


async def researcher_node(state: AgentState, mcp_tools: list) -> AgentState:
    """AraÅŸtÄ±rmacÄ±: Web aramasÄ± yapar"""
    try:
        logger.info("[SEARCH] Researcher baÅŸladÄ±...")
        model = get_llm_model()
        
        search_tools = [t for t in mcp_tools if any(
            name in t.name.lower() 
            for name in ['search', 'scrape', 'tavily', 'firecrawl']
        )]
        
        if not search_tools:
            raise ValueError("Arama tool'u bulunamadÄ±")
        
        researcher = create_deep_agent(
            model=model,
            tools=search_tools,
            system_prompt=RESEARCHER_PROMPT.format(query=state["query"]),
        )
        
        result = await researcher.ainvoke(
            {"messages": [{"role": "user", "content": state["query"]}]},
            config={"recursion_limit": 8}  # ArtÄ±rÄ±ldÄ±: 5 â†’ 8
        )
        
        research_results = ""
        if "messages" in result:
            for msg in reversed(result["messages"]):
                if hasattr(msg, 'content') and isinstance(msg.content, str) and msg.content.strip():
                    research_results = msg.content
                    break
        
        state["research_results"] = research_results or "Arama sonucu bulunamadÄ±"
        state["messages"].append(AIMessage(content=f"[SEARCH] AraÅŸtÄ±rma tamamlandÄ±"))
        logger.info("[OK] Researcher tamamlandÄ±")
        
    except Exception as e:
        logger.error(f"[ERROR] Researcher Error: {str(e)}", exc_info=True)
        state["research_results"] = "AraÅŸtÄ±rma baÅŸarÄ±sÄ±z"
        state["messages"].append(AIMessage(content=f"âš ï¸ AraÅŸtÄ±rma hatasÄ±, devam ediliyor"))
    
    # Next agent belirleme
    if "coder" in state.get("supervisor_plan", "").lower():
        state["next_agent"] = "coder"
    else:
        state["next_agent"] = "writer"
    
    return state


async def coder_node(state: AgentState) -> AgentState:
    """Kodcu: Kod Ã¶rnekleri oluÅŸturur"""
    try:
        logger.info("ğŸ’» Coder baÅŸladÄ±...")
        model = get_llm_model()
        
        coder = create_deep_agent(
            model=model,
            tools=[],
            system_prompt=CODER_PROMPT.format(
                query=state["query"],
                research_results=state.get("research_results", "")
            ),
        )
        
        result = await coder.ainvoke(
            {"messages": [{"role": "user", "content": "Kod Ã¶rnekleri oluÅŸtur"}]},
            config={"recursion_limit": 20}  # ArtÄ±rÄ±ldÄ±: 2 â†’ 20
        )
        
        code_examples = ""
        if "messages" in result:
            for msg in reversed(result["messages"]):
                if hasattr(msg, 'content') and isinstance(msg.content, str) and msg.content.strip():
                    code_examples = msg.content
                    break
        
        state["code_examples"] = code_examples or "Kod Ã¶rneÄŸi oluÅŸturulamadÄ±"
        state["messages"].append(AIMessage(content=f"ğŸ’» Kod Ã¶rnekleri hazÄ±rlandÄ±"))
        logger.info("[OK] Coder tamamlandÄ±")
        
    except Exception as e:
        logger.error(f"[ERROR] Coder Error: {str(e)}", exc_info=True)
        state["code_examples"] = "Kod Ã¶rnekleri oluÅŸturulamadÄ±"
        state["messages"].append(AIMessage(content=f"âš ï¸ Kod oluÅŸturma hatasÄ±"))
    
    state["next_agent"] = "writer"
    return state


async def writer_node(state: AgentState) -> AgentState:
    """Yazar: Final raporu oluÅŸturur"""
    try:
        logger.info("ğŸ“ Writer baÅŸladÄ±...")
        model = get_llm_model()
        
        writer = create_deep_agent(
            model=model,
            tools=[],
            system_prompt=WRITER_PROMPT.format(
                query=state["query"],
                research_results=state.get("research_results", ""),
                code_examples=state.get("code_examples", "")
            ),
        )
        
        result = await writer.ainvoke(
            {"messages": [{"role": "user", "content": "Profesyonel rapor yaz"}]},
            config={"recursion_limit": 25}  # ArtÄ±rÄ±ldÄ±: 5 â†’ 25
        )
        
        final_report = ""
        if "messages" in result:
            for msg in reversed(result["messages"]):
                if hasattr(msg, 'content') and isinstance(msg.content, str) and msg.content.strip():
                    final_report = msg.content
                    break
        
        if not final_report:
            # Fallback rapor
            final_report = f"""# {state['query']}

## AraÅŸtÄ±rma SonuÃ§larÄ±
{state.get('research_results', 'Bilgi bulunamadÄ±')}

## Kod Ã–rnekleri
{state.get('code_examples', 'Ã–rnek bulunamadÄ±')}
"""
        
        state["final_report"] = final_report
        state["messages"].append(AIMessage(content=f"ğŸ“ Rapor tamamlandÄ±"))
        logger.info("[OK] Writer tamamlandÄ±")
        
    except Exception as e:
        logger.error(f"[ERROR] Writer Error: {str(e)}", exc_info=True)
        state["final_report"] = f"# Rapor OluÅŸturulamadÄ±\n\nHata: {str(e)}"
        state["messages"].append(AIMessage(content=f"âš ï¸ Rapor yazma hatasÄ±"))
    
    state["next_agent"] = "END"
    return state


# =============================================================================
# ROUTER
# =============================================================================

def route_agent(state: AgentState) -> Literal["researcher", "coder", "writer", "END"]:
    """Bir sonraki agentÄ± belirler"""
    next_agent = state.get("next_agent", "END")
    
    if next_agent == "END":
        return END
    return next_agent


# =============================================================================
# GRAPH BUILDER
# =============================================================================

async def create_multi_agent_system():
    """Multi-Agent sistemi oluÅŸturur"""
    
    logger.info("ğŸ”Œ MCP Servers baÄŸlanÄ±yor...")
    
    mcp_servers = {
        "firecrawl": {
            "command": settings.firecrawl_mcp_command,
            "args": settings.firecrawl_mcp_args,
            "env": settings.get_firecrawl_env(),
            "transport": "stdio"
        }
    }
    
    if hasattr(settings, 'tavily_api_key') and settings.tavily_api_key:
        mcp_servers["tavily"] = {
            "command": "npx",
            "args": ["-y", "tavily-mcp@latest"],
            "env": {"TAVILY_API_KEY": settings.tavily_api_key},
            "transport": "stdio"
        }
    
    mcp_client = MultiServerMCPClient(mcp_servers)
    mcp_tools = await mcp_client.get_tools()
    
    for tool in mcp_tools:
        sanitize_tool_schema(tool)
    
    logger.info(f"[OK] {len(mcp_tools)} tool yÃ¼klendi")
    
    # Graph oluÅŸtur
    workflow = StateGraph(AgentState)
    
    # Node'larÄ± ekle - LAMBDA YERINE DOÄRUDAN ASYNC WRAPPER
    async def researcher_wrapper(state: AgentState) -> AgentState:
        return await researcher_node(state, mcp_tools)
    
    workflow.add_node("supervisor", supervisor_node)
    workflow.add_node("researcher", researcher_wrapper)
    workflow.add_node("coder", coder_node)
    workflow.add_node("writer", writer_node)
    
    # Edge'leri ekle
    workflow.set_entry_point("supervisor")
    
    # Supervisor'dan routing
    workflow.add_conditional_edges(
        "supervisor",
        route_agent,
        {
            "researcher": "researcher",
            "coder": "coder",
            "writer": "writer",
            "END": END
        }
    )
    
    # Researcher'dan routing
    workflow.add_conditional_edges(
        "researcher",
        route_agent,
        {
            "coder": "coder",
            "writer": "writer",
            "END": END
        }
    )
    
    # Coder'dan routing
    workflow.add_conditional_edges(
        "coder",
        route_agent,
        {
            "writer": "writer",
            "END": END
        }
    )
    
    # Writer'dan END
    workflow.add_edge("writer", END)
    
    # Compile
    app = workflow.compile()
    
    logger.info("[OK] Multi-Agent sistem hazÄ±r!")
    return app, mcp_client


# =============================================================================
# RUN FUNCTION
# =============================================================================

async def run_multi_agent_research(query: str, verbose: bool = True) -> str:
    """Multi-agent sistemi Ã§alÄ±ÅŸtÄ±rÄ±r"""
    
    app, mcp_client = await create_multi_agent_system()
    
    # Initial state
    initial_state = {
        "messages": [],
        "query": query,
        "research_results": "",
        "code_examples": "",
        "final_report": "",
        "next_agent": "",
        "supervisor_plan": "",
        "supervisor_reason": ""
    }
    
    if verbose:
        print("[START] Multi-Agent araÅŸtÄ±rma baÅŸlatÄ±lÄ±yor...\n")
    
    try:
        result = await app.ainvoke(
            initial_state,
            config={"recursion_limit": 15}
        )
        
        final_report = result.get("final_report", "Rapor oluÅŸturulamadÄ±")
        
        if verbose:
            print("\n" + "="*70)
            print("ğŸ“Š SONUÃ‡")
            print("="*70)
            print(final_report)
            print("="*70)
        
        return final_report
        
    except Exception as e:
        logger.error(f"[ERROR] Run Error: {str(e)}", exc_info=True)
        return f"Sistem hatasÄ±: {str(e)}"
    finally:
        # MCP client'Ä± temizle
        try:
            await mcp_client.cleanup()
        except:
            pass 